
save_dir: outputs/camera_a2b/teaching
mode: teaching
model:
  arch:
    name: OneStageDetector
    backbone:
      name: ShuffleNetV2
      model_size: 0.5x
      out_stages: [2,3,4]
      activation: LeakyReLU
    fpn:
      name: PAN
      in_channels: [48, 96, 192]
      out_channels: 96
      start_level: 0
      num_outs: 3
    head:
      enable: True
      name: NanoDetHead
      num_classes: 4
      input_channel: 96
      feat_channels: 96
      stacked_convs: 2
      share_cls_reg: True
      octave_base_scale: 5
      scales_per_octave: 1
      strides: [8, 16, 32]
      reg_max: 7
      norm_cfg:
        type: BN
      loss:
        loss_qfl:
          name: QualityFocalLoss
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:
          name: GIoULoss
          loss_weight: 2.0
data:
  # data_root: /scratch/generalvision/zhaozijing/data
  data_root: /network_space/storage43/zhaozijing/datasets
  train:
    name: CocoDataset
    img_path: tencent/camera_a
    ann_path: tencent/camera_a/annotations/train_coco_style.json
    tgt_img_path: tencent/camera_b
    tgt_ann_path: tencent/camera_b/annotations/train_coco_style.json
    input_size: [448,256] #[w,h]
    keep_ratio: True
    pipeline:
      perspective: 0.0
      scale: [0.5, 1.5]
      stretch: [[1, 1], [1, 1]]
      rotation: 0
      shear: 0
      translate: 0.2
      flip: 0.5
      brightness: 0.2
      contrast: [0.6, 1.4]
      saturation: [0.5, 1.2]
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
  val:
    name: CocoDataset
    img_path: tencent/camera_b
    ann_path: tencent/camera_b/annotations/val_coco_style.json
    input_size: [448,256] #[w,h]
    keep_ratio: True
    pipeline:
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
tgt_loss_scale: 0.5
threshold:
  start_value: 0.4
  max_value: 0.4
  min_value: 0.4
  gamma: 0.9
ema_alpha: 0.9996
device:
  gpu_ids: [0, 1]
  workers_per_gpu: 8
  batchsize_per_gpu: 24
schedule:
  load_model: ./checkpoints/camera_a2b/source_only.ckpt
  optimizer:
    name: SGD
    lr: 0.02
    momentum: 0.9
    weight_decay: 0.0001
  warmup:
    name: linear
    steps: 1000
    ratio: 0.00001
  total_epochs: 100
  lr_schedule:
    name: MultiStepLR
    milestones: [50, 90]
    gamma: 0.1
  val_intervals: 5
evaluator:
  name: CocoDetectionEvaluator
  save_key: AP_50

log:
  interval: 50

class_names: ['pedestrian', 'sign', 'vehicle', 'arrow']
